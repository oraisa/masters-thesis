%% This file is modified by Veli Mäkinen from HY_fysiikka_LuKtemplate.tex authored by Roope Halonen ja Tomi Vainio.
%% Some text is also inherited from engl_malli.tex by Kutvonen, Erkiö, Mäkelä, Verkamo, Kurhila, and Nykänen.


% STEP 1: Choose oneside or twoside
\documentclass[english,twoside,openright]{HYgraduMLDS}
%finnish,swedish

\usepackage{lmodern} % Font package
\usepackage{textcomp} % Package for special symbols
\usepackage[pdftex]{color, graphicx} % For pdf output and jpg/png graphics
\usepackage[pdftex, plainpages=false]{hyperref} % For hyperlinks and pdf metadata
\usepackage{fancyhdr} % For nicer page headers
\usepackage{tikz} % For making vector graphics (hard to learn but powerful)
%\usepackage{wrapfig} % For nice text-wrapping figures (use at own discretion)
\usepackage{amsmath, amssymb} % For better math
\usepackage{amsthm}
%\usepackage[square]{natbib} % For bibliography
\usepackage[footnotesize,bf]{caption} % For more control over figure captions
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage[titletoc]{appendix}
\usepackage[ruled, vlined]{algorithm2e}

\onehalfspacing %line spacing
%\singlespacing
%\doublespacing

%\fussy 
\sloppy % sloppy and fussy commands can be used to avoid overlong text lines

% STEP 2:
% Set up all the information for the title page and the abstract form.
% Replace parameters with your information.
\title{Differentially Private Markov Chain Monte Carlo}
\author{Ossi Räisä}
\date{\today}
\prof{Professor Antti Honkela}
\censors{Professor Antti Honkela}{Dr. Antti Koskela}{}
\keywords{Differential Privacy, Markov Chain Monte Carlo}
\depositeplace{}
\additionalinformation{}


\classification{\protect{\ \\
% \  General and reference $\rightarrow$ Document types  $\rightarrow$ Surveys and overviews\  \\
% \  Applied computing  $\rightarrow$ Document management and text processing  $\rightarrow$ Document management $\rightarrow$ Text editing\\
}}

% if you want to quote someone special. You can comment this line and there will be nothing on the document.
%\quoting{Bachelor's degrees make pretty good placemats if you get them laminated.}{Jeph Jacques} 


% OPTIONAL STEP: Set up properties and metadata for the pdf file that pdfLaTeX makes.
% But you don't really need to do this unless you want to.
\hypersetup{
    % bookmarks=true,         % show bookmarks bar first?
    unicode=true,           % to show non-Latin characters in Acrobatâs bookmarks
    pdftoolbar=true,        % show Acrobatâs toolbar?
    pdfmenubar=true,        % show Acrobatâs menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={},            % title
    pdfauthor={},           % author
    pdfsubject={},          % subject of the document
    pdfcreator={},          % creator of the document
    pdfproducer={pdfLaTeX}, % producer of the document
    pdfkeywords={something} {something else}, % list of keywords for
    pdfnewwindow=true,      % links in new window
    colorlinks=true,        % false: boxed links; true: colored links
    linkcolor=black,        % color of internal links
    citecolor=black,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\cl}[1]{\overline{#1}}
\newcommand{\kl}{D_{\mathrm{KL}}}
\newcommand{\dmid}{\mid\mid}
\newcommand{\var}{\mathrm{Var}}
\newcommand{\calm}{{\mathcal{M}}}
\newcommand{\calx}{{\mathcal{X}}}
\newcommand{\calu}{{\mathcal{U}}}
\newcommand{\caln}{{\mathcal{N}}}
\newcommand{\call}{{\mathcal{L}}}
\newcommand{\caly}{{\mathcal{Y}}}
\DeclareMathOperator{\erfc}{erfc}

\begin{document}

% Generate title page.
\maketitle

% STEP 3:
% Write your abstract (of course you really do this last).
% You can make several abstract pages (if you want it in different languages),
% but you should also then redefine some of the above parameters in the proper
% language as well, in between the abstract definitions.

\begin{abstract}
 
\end{abstract}

% Place ToC
\mytableofcontents

\mynomenclature

% -----------------------------------------------------------------------------------
% STEP 4: Write the thesis.
% Your actual text starts here. You shouldn't mess with the code above the line except
% to change the parameters. Removing the abstract and ToC commands will mess up stuff.
\chapter{Introduction}

\chapter{Background}

\section{Differential Privacy}\label{DP_background}

Differential privacy~\cite{DwR14} is a property of an algorithm that quantifies the 
amount of information about private data an adversary can gain from the 
publication of the algorithm's output.
The most commonly used definition uses two real numbers, 
\(\epsilon\) and \(\delta\), to quantify the information gain, or, from the 
perspective of a data subject, the privacy loss of the algorithm.

The most common definition is called \((\epsilon, \delta)\)-DP, approximate DP 
or ADP~\cite{DwR14}.
The case where \(\delta = 0\) is called \(\epsilon\)-DP or 
pure DP.

\begin{definition}\label{ADP-definition}
    An algorithm \(\calm\colon \calx \to \calu\) is \((\epsilon, \delta)\)-ADP if 
    for all neighbouring inputs \(x\in \calx\) and \(x'\in \calx\) and 
    all measurable sets \(S \subset \calu\)
    \[
        P(\calm(x)\in S) \leq e^\epsilon P(\calm(x')\in S) + \delta
    \]
\end{definition}

The neighbourhood relation in the definition is domain specific. With tabular 
data the most common definitions are the add/remove neighbourhood and 
substitute neighbourhood.
\begin{definition}
    Two tabular datasets are said to be add/remove neighbours if they are equal 
    after adding or removing at most one row to or from one of them. The datasets 
    are said to be in substitute neighbours if they are equal after 
    changing at most one row in one of them.
\end{definition}
The neighbourhood relation is denoted by \(\sim\). The definitions and 
theorems of this section are valid for all neighbourhood relations.

There many other definitions of differential privacy that are mostly used 
to compute \((\epsilon, \delta)\)-bounds for ADP. This thesis uses two of them: 
Rényi-DP (RDP)~\cite{Mironov17} and 
zero-concentrated differential privacy (zCDP)~\cite{BuS16}. Both are based 
on Rényi divergence~\cite{Mironov17}, which is a particular way of 
measuring the difference between random variables.

\begin{definition}
    For random variables with density or probability mass functions 
    \(P\) and \(Q\) the Rényi divergence of order 
    \(1 < \alpha < \infty\) is
    \[
        D_\alpha(P\dmid Q) = \frac{1}{\alpha - 1}\ln E_{x\sim Q}
        \left(\frac{P(x)^\alpha}{Q(y)^\alpha}\right)
    \]
    Orders \(\alpha = 1\) and \(\alpha = \infty\) are defined 
    by continuity:
    \[
        D_1(P\dmid Q) = \lim_{\alpha \to 1-} D_\alpha(P\dmid Q)
    \]
    \[
        D_\infty(P \dmid Q) = \lim_{\alpha\to \infty}D_\alpha(P\dmid Q)
    \]
\end{definition}

Both Rényi-DP and zCDP can be expressed as bounds on the 
Rényi divergence between the outputs of an algorithm with 
neighbouring inputs:

\begin{definition}
    An algorithm \(\calm\) is \((\alpha, \epsilon)\)-Rényi DP 
    if for all \(x \sim x'\)
    \[
        D_\alpha(\calm(x)\dmid \calm(x')) \leq \epsilon
    \]
    \(\calm\) is \(\rho\)-zCDP if for all \(\alpha > 1\)
    and all \(x \sim x'\)
    \[
        D_\alpha(\calm(x)\dmid \calm(x')) \leq \rho \alpha
    \]

\end{definition}

A very useful property of all of these definitions is composition~\cite{DwR14}: 
if algorithms \(\calm\) and \(\calm'\) are DP, the algorithm first computing 
\(\calm\) and then \(\calm'\), outputting both results, 
is also DP, although with worse bounds.
More precisely

\begin{definition}
    Let \(\calm\colon \calx \to \calu\) and 
    \(\calm'\colon \calx\times \calu \to \calu'\) be algorithms.
    Their composition is the algorithm outputting 
    \((\calm(x), \calm'(x, \calm(x)))\) for input \(x\).
\end{definition}

\begin{theorem}\label{composition-theorem}
    Let \(\calm\colon \calx \to \calu\) and 
    \(\calm\colon \calx\times \calu \to \calu'\) be algorithms. Then 
    \begin{enumerate}
        \item 
            If \(\calm\) is \((\epsilon, \delta)\)-ADP and 
            \(\calm'\) is \((\epsilon', \delta')\)-ADP, then 
            their composition is 
            \((\epsilon + \epsilon', \delta + \delta')\)-ADP~\cite{DwR14}
        \item 
            If \(\calm\) is \((\alpha, \epsilon)\)-RDP and 
            \(\calm'\) is \((\alpha, \epsilon')\)-RDP, then 
            their composition is \((\alpha, \epsilon + \epsilon')\)-RDP~\cite{Mironov17}
        \item 
            If \(\calm\) is \(\rho\)-zCDP and 
            \(\calm'\) is \(\rho'\)-zCDP, then 
            their composition is \((\rho + \rho')\)-zCDP~\cite{BuS16}
    \end{enumerate}
\end{theorem}

All of the composition results can be extended to any number of compositions 
by induction. Note that any step of the composition can depend on the results 
of the previous steps, not only on the private data.

As any algorithm that does not use private data in any way is 
\((0, 0)\)-ADP, 0-zCDP and \((\alpha, 0)\)-RDP with all \(\alpha\), 
theorem~\ref{composition-theorem} has the following corollary, called 
post-processing immunity:

\begin{theorem}
    Let \(\calm\colon \calx\to \calu\) be an ADP, RDP or zCDP algorithm with 
    some privacy parameters. Let \(f\colon \calu\to \calu'\) be any algorithm 
    not using the private data. Then the composition of \(\calm\) and \(f\)
    is ADP, RDP or zCDP with the same privacy parameters.
\end{theorem}

There are many different DP algorithms that are commonly used, which are also
called mechanisms~\cite{DwR14}. This thesis only requires one of the most commonly 
used ones: the Gaussian mechanism~\cite{DwR14}.
\begin{definition}
    The Gaussian mechanism with parameter \(\sigma^2\) 
    is an algorithm that, with input \(x\), 
    outputs a sample from \(\caln(x, \sigma^2)\), where \(\caln\) denotes 
    the normal distribution.
\end{definition}

The RDP and zCDP bounds for the Gaussian 
mechanism are quite simple. The ADP bound is more complicated:

\begin{theorem}\label{gauss-DP-bounds}
    If for all inputs \(x\) and \(x'\), \(||x - x'||_2 \leq \Delta\),
    the Gaussian mechanism is 
    \begin{enumerate}
        \item 
            \((\alpha, \frac{\alpha \Delta^2}{2\sigma^2})\)-RDP~\cite{Mironov17}
        \item 
            \(\frac{\Delta^2}{2\sigma^2}\)-zCDP~\cite{BuS16}
        \item 
            \(n\) compositions of the Gaussian mechanism are 
            \((\epsilon, \delta(\epsilon))\)-ADP~\cite{Sommer2019} with 
            \[
                \delta(\epsilon) 
                = \frac{1}{2}\left(
                    \erfc\left(\frac{\sigma(\epsilon - n\mu)}{\sqrt{2n}\Delta}\right)
                    - e^\epsilon \erfc\left(\frac{\sigma(\epsilon + n\mu)}{\sqrt{2n}\Delta}\right)
                \right)
            \]
            where \(\mu = \frac{\Delta^2}{2\sigma^2}\) and \(\erfc\) is 
            the complementary error function.
    \end{enumerate}
\end{theorem}

The most common use case for the Gaussian mechanism is computing a 
function \(f\colon \calx \to \R\) of private data and feeding the result into 
the Gaussian mechanism to privately release the function value. 
The condition that the inputs 
of the Gaussian mechanism cannot vary too much leads into the concept of 
sensitivity of a function
\begin{definition}
    The \(l_p\)-sensitivity \(\Delta_p\), with neighbourhood relation \(\sim\),
    of a function \(f\colon \calx \to \R^n\)
    is 
    \[
        \Delta_p f = \sup_{x\sim x'}||f(x) - f(x')||_p
    \]
\end{definition}

Theorem \ref{gauss-DP-bounds} implies that the value of any function with 
finite \(l_2\)-sensitivity can be privately released using the Gaussian mechanism 
with appropriate noise variance \(\sigma^2\). Of course, the usefulness of the 
released value depends on the magnitude of \(\sigma^2\) compared to the actual 
value.

\section{Bayesian Inference and Markov Chain Monte Carlo}\label{MCMC_background}

In Bayesian inference, the parameters of a statistical model are inferred from 
observed data using Bayes' theorem~\cite{BDA}. The result is not just a point estimate 
of the parameters, but a probability distribution describing the likelihood 
of different values of the parameters.

Bayes' theorem relates the \emph{posterior} belief of the parameters 
\(p(\theta \mid D)\) to the \emph{prior} belief \(p(\theta)\) through the 
observed data \(D\) and the likelihood of the data \(p(D\mid \theta)\) as follows:
\[
    p(\theta \mid D) = \frac{p(D \mid \theta)p(\theta)}
    {\int p(D\mid \theta)p(\theta)d\theta}
\]
It is theoretically possible to compute \(p(\theta \mid D)\) given any 
likelihood, prior and data, but the integral in the denominator is in many 
cases difficult to compute~\cite{BDA}. In such cases the posterior cannot be feasibly 
computed. However, many of the commonly used summary statistics of the posterior, 
such as the mean, variance and credible intervals, can be approximated from 
a sample of the posterior. \emph{Markov chain Monte Carlo} (MCMC) is a 
widely used algorithm to obtain such samples~\cite{BDA}.

Markov chain Monte Carlo algorithms sequentially sample values of \(\theta\)
with the goal of eventually having the chain of sampled values converge to 
a given distribution~\cite{BDA}. While this can be done in many ways, this thesis 
focuses on a particular MCMC algorithm: \emph{Metropolis-Hastings} (MH).

The Metropolis-Hastings algorithm samples from a distribution \(\pi\) of 
\(\theta_i\) by first picking a proposal \(\theta^*\) from a proposal 
distribution \(q(\theta_{i-1})\) at iteration \(i\)~\cite{BDA}.
A density ratio is calculated
\[
    r = \frac{\pi(\theta^*)}{\pi(\theta_{i-1})}
    \frac{q(\theta_{i-1}\mid \theta^*)}{q(\theta^*\mid \theta_{i-1})}
\]
and the proposal is accepted with probability \(\min\{1, r\}\). 
If the proposal is accepted, 
\(\theta_i = \theta^*\), otherwise \(\theta_i = \theta_{i-1}\).

It can be shown that, with a suitable proposal distribution, the chain of 
\(\theta_i\) values converges to \(\pi\)~\cite{BDA}. The Gaussian distribution centered 
at the current value is a commonly used proposal.

When MCMC is used in Bayesian inference, the distribution to approximate is 
\[
    \pi(\theta) = p(\theta \mid D) = \frac{p(D \mid \theta)p(\theta)}
    {\int p(D\mid \theta)p(\theta)d\theta}
\]
The difficult integral \(\int p(D\mid \theta)p(\theta)d\theta\) in the denominator 
cancels out when computing \(r\), so only the likelihood and prior are needed. 
For numerical stability, \(r\) is usually computed in 
log space, which makes the acceptance probability \(\min\{1, e^\lambda\}\)
where 
\[
    \lambda = \ln \frac{p(\theta^* \mid D)}{p(\theta_{i-1}\mid D)}
    + \ln \frac{p(\theta^*)}{p(\theta_{i-1})}
    + \ln \frac{q(\theta_{i-1}\mid \theta^*)}{q(\theta^*\mid \theta_{i-1})}
\]

The dataset \(D\) is typically a table with \(n\) independent rows.
The likelihood is given as 
\[
    p(\theta\mid D_j)
\]
for row \(D_j\). The independence means that 
\[
    p(\theta\mid D) = \prod_{j=1}^k p(\theta\mid D_j)
\]
which means that the log likelihood ratio term of \(\lambda\) is 
\[
    \ln \frac{p(\theta^*\mid D)}{p(\theta_{i-1}\mid D)}
    = \sum_{j=1}^n \ln\frac{p(\theta^*\mid D_j)}{p(\theta_{i-1}\mid D_j)}
\]
Algorithm~\ref{MH_algo} puts all of this together to summarise the MH 
algorithm used for Bayesian inference.

\begin{algorithm}[H]\label{MH_algo}
    \SetAlgoLined
    \For{\(1 \leq i \leq k\)}{
        sample \(\theta^* \sim q(\theta_{i-1})\)\\
        \(\lambda = 
        \sum_{j=1}^n \ln\frac{p(\theta^*\mid D_j)}{p(\theta_{i-1}\mid D_j)}
        + \ln \frac{p(\theta^*)}{p(\theta_{i-1})}
        + \ln \frac{q(\theta_{i-1}\mid \theta^*)}{q(\theta^*\mid \theta_{i-1})}\)
        \\
        \(\theta_i = \begin{cases}
            \theta^* & \text{ with probability } \min\{1, e^\lambda\} \\
            \theta_{i-1} & \text{ otherwise}
        \end{cases}
        \)\\
    }
    \Return \((\theta_1, \dotsc, \theta_k)\)
    \caption{
        Metropolis-Hastings: number of iterations \(k\), proposal 
        distribution \(q\) and initial value \(\theta_0\) and 
        dataset \(D\) as input
    }
\end{algorithm}

\chapter{Differentially Private MCMC}

As seen in Section~\ref{DP_background}, an algorithm can be made differentially 
private by adding Gaussian noise the its output. The noise could also be added 
to any intermediate value calculated by the algorithm, and post processing immunity 
will guarantee that the same DP bounds that hold for releasing the intermediate 
value also hold for releasing the final result of the algorithm.

In 2019, Yildirim and Ermis~\cite{YildirimE19} realised that if Gaussian noise is added to 
the exact value of \(\lambda\), the noise can be corrected for 
yielding a differentially private MCMC algorithm which converges to 
the correct distribution. In the same year, Heikkilä et.\ al.~\cite{HeikkilaJDH19}
developed another DP MCMC algorithm, called DP Barker, which uses subsampling 
to amplify privacy.

\section{DP Penalty}

In 1999, Ceperley and Dewing~\cite{CeD99} developed a variant of 
Metropolis-Hastings called the penalty 
algorithm, where only a noisy approximation of \(\lambda\) is known. They 
developed the algorithm for simulations in physics where computing \(\lambda\)
requires computing energies of complex systems, which can only be approximated.
The penalty algorithm modifies the acceptance probability to account for the 
noise added to \(\lambda\) and still converges to the correct distribution if 
the noise is Gaussian with known variance.

\section{DP Barker}

The DP Barker algorithm of Heikkilä et.\ al.~\cite{HeikkilaJDH19} is based on 
the Barker acceptance test~\cite{Barker65} instead of the Metropolis-Hastings test.
Instead of using the MH acceptance probability, the Barker acceptance test samples 
\(V_{log}\sim \mathrm{Logistic(0, 1)}\) and accepts if 
\[
    \lambda + V_{log} > 0
\]

If Gaussian noise with variance \(\sigma^2\) is added to 
\(\lambda\), there exists a correction 
distribution \(V_{corr}\) such that \(\caln(0, \sigma^2) + V_{corr}\) has the 
same distribution as \(V_{log}\). Because the variance of \(V_{log}\) is 
\(\frac{\pi^2}{3}\), the variance of \(V_{corr}\) must be 
\(\frac{\pi^2}{3} - \sigma^2\) which means that there is an upper bound
to the noise variance: \(\sigma^2 < \frac{\pi^2}{3}\). Testing whether 
\(\lambda + \caln(0, \sigma^2) + V_{corr} > 0\) is equivalent to testing 
whether \(\lambda + V_{log} > 0\), which means that it is possible to derive 
a DP MCMC algorithm based on the Barker acceptance test if the correction 
distribution can be sampled from.

However, the analytical form of \(V_{corr}\) is not known~\cite{HeikkilaJDH19}.
Heikkilä et.\ al.~\cite{HeikkilaJDH19} derive a method to accurately approximate 
the distribution and draw samples from the approximation. This means that their 
algorithm does only approximately converges to the correct distribution, but the 
error in approximating \(V_{corr}\) can be made very small.

If the sum in \(\lambda\) was only computed over a subset of the data, the 
algorithm would take less computation to run, and would be less sensitive 
to changes in the data. The latter property is called \emph{subsampling amplification}
of differential privacy~\cite{WangBK19}. The using the \(\lambda\) computed 
with subsampling instead of the full data \(\lambda\) introduces an additional 
error that must be correct for to have the algorithm converge to the correct 
distribution. 

The \emph{central limit theorem} (CLT) states that the distribution of a sum 
of random variables approaches a Gaussian distribution as more random variables 
are summed, if some conditions on the independence and variance of the random 
variables are met~\cite{HeikkilaJDH19}. With the CLT, it can be argued 
that the error from 
using the subsampled \(\lambda\) instead of the full data \(\lambda\) has an 
approximately Gaussian distribution, if the subsample is large 
enough~\cite{HeikkilaJDH19}. 

The variance of the error from subsampling can 
be estimated by the sample variance of the individual terms in the sum in 
\(\lambda\)~\cite{HeikkilaJDH19}. This allows combining the errors from subsampling and the 
Gaussian noise from the Gaussian mechanism to a single Gaussian noise value.
The \(V_{corr}\) distribution can then be used to approximate the Barker acceptance 
test as above. See algorithm~\ref{DP_barker_algo} for the DP Barker algorithm
\footnote{
    See \cite{HeikkilaJDH19} for the sampling procedure of \(V_{corr}\).
}.

\begin{algorithm}[H]\label{DP_barker_algo}
    \SetAlgoLined
    sample \(\theta^* \sim q(\theta_{i-1})\)\\
    sample \(B \subset \{1, \dotsc, n\}\)\\
    \For{\(1 \leq i \leq k\)}{
        \For{\(j \in B\)}{
            \(l_j = \ln \frac{p(\theta^*\mid D_j)}{p(\theta_{i-1}\mid D_j)}\)\\
        }
        \(\sigma^2_b = \mathrm{Var}\{l_j\mid j\in B\}\)\\
        \(\lambda = 
        \frac{nT}{|B|}\sum_{j\in B} l_j
        + \ln \frac{p(\theta^*)}{p(\theta_{i-1})}
        + \ln \frac{q(\theta_{i-1}\mid \theta^*)}{q(\theta^*\mid \theta_{i-1})}\)
        \\
        sample \(s \sim \caln(0, \sigma^2 - \sigma^2_b)\)\\
        sample \(c \sim V_{corr}^{\sigma^2}\)\\
        \(\theta_i = \begin{cases}
            \theta^* & \text{ if } \lambda + s + c > 0 \\
            \theta_{i-1} & \text{ otherwise}
        \end{cases}
        \)\\
    }
    \Return \((\theta_1, \dotsc, \theta_k)\)
    \caption{
        DP Barker
    }
\end{algorithm}

\section{Comparing DP Penalty and DP Barker}

\chapter{Variations of the Penalty Algorithm}

\section{The Penalty Algorithm with Subsampling}

\section{DP Metropolis-Adjusted Langevin Algorithm}

\chapter{The Gauss-Bernoulli Algorithm}

\chapter{Experiments}

\chapter{Conclusions}
% STEP 5:
% Uncomment the following lines and set your .bib file and desired bibliography style
% to make a bibliography with BibTeX.
% Alternatively you can use the thebibliography environment if you want to add all
% references by hand.

\cleardoublepage %fixes the position of bibliography in bookmarks
\phantomsection

\addcontentsline{toc}{chapter}{\bibname} % This lines adds the bibliography to the ToC
\bibliographystyle{abbrv} % numbering alphabetic order
\bibliography{../references.bib}

% \begin{appendices}
% \myappendixtitle
%
% \chapter{Code example\label{appendix:code}}
% Program code can be added as appendix:
% \begin{verbatim}
% #!/bin/bash          
% text="Hello World!"
% echo $text
% \end{verbatim}
%
% \end{appendices}

\end{document}
